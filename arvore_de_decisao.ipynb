{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308291b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class NoDecisao:\n",
    "    def __init__(self, caracteristica=None, limite=None, esquerda=None, \n",
    "                 direita=None, valor=None, ganho=None, n_amostras=None):\n",
    "        self.valor = valor\n",
    "        self.caracteristica = caracteristica\n",
    "        self.limite = limite\n",
    "        self.esquerda = esquerda\n",
    "        self.direita = direita\n",
    "        self.ganho = ganho  # Ganho de informa√ß√£o da divis√£o\n",
    "        self.n_amostras = n_amostras  # N√∫mero de amostras no n√≥\n",
    "\n",
    "class ArvoreDecisaoAprimorada:\n",
    "    def __init__(self, profundidade_maxima=10, min_amostras_divisao=2, \n",
    "                 min_ganho_informacao=0.01, tipo='classificacao'):\n",
    "        self.profundidade_maxima = profundidade_maxima\n",
    "        self.min_amostras_divisao = min_amostras_divisao\n",
    "        self.min_ganho_informacao = min_ganho_informacao\n",
    "        self.tipo = tipo\n",
    "        self.raiz = None\n",
    "        self.importancias = None\n",
    "    \n",
    "    def ajustar(self, dados, rotulos):\n",
    "        self.raiz = self._construir_arvore(dados, rotulos)\n",
    "        self._calcular_importancias()\n",
    "        return self\n",
    "    \n",
    "    # --- M√âTRICAS ---\n",
    "    \n",
    "    def _entropia(self, rotulos):\n",
    "        if len(rotulos) == 0:\n",
    "            return 0\n",
    "        _, contagens = np.unique(rotulos, return_counts=True)\n",
    "        probabilidades = contagens / len(rotulos)\n",
    "        return -np.sum(probabilidades * np.log2(probabilidades + 1e-8))\n",
    "    \n",
    "    def _ganho_informacao(self, rotulos_pai, rotulos_esquerda, rotulos_direita):\n",
    "        if len(rotulos_pai) == 0:\n",
    "            return 0\n",
    "        \n",
    "        entropia_pai = self._entropia(rotulos_pai)\n",
    "        peso_esquerda = len(rotulos_esquerda) / len(rotulos_pai)\n",
    "        peso_direita = len(rotulos_direita) / len(rotulos_pai)\n",
    "        \n",
    "        entropia_filhos = (peso_esquerda * self._entropia(rotulos_esquerda) + \n",
    "                          peso_direita * self._entropia(rotulos_direita))\n",
    "        \n",
    "        return entropia_pai - entropia_filhos\n",
    "    \n",
    "    def _impureza_gini(self, rotulos):\n",
    "        \"\"\"Alternativa √† entropia - mais r√°pida computacionalmente\"\"\"\n",
    "        if len(rotulos) == 0:\n",
    "            return 0\n",
    "        _, contagens = np.unique(rotulos, return_counts=True)\n",
    "        probabilidades = contagens / len(rotulos)\n",
    "        return 1 - np.sum(probabilidades ** 2)\n",
    "    \n",
    "    # --- DIVIS√ÉO ---\n",
    "    \n",
    "    def _melhor_divisao(self, dados, rotulos):\n",
    "        melhor_ganho = -1\n",
    "        melhor_caracteristica = None\n",
    "        melhor_limite = None\n",
    "        \n",
    "        n_amostras, n_caracteristicas = dados.shape\n",
    "        \n",
    "        for idx_caracteristica in range(n_caracteristicas):\n",
    "            caracteristica = dados[:, idx_caracteristica]\n",
    "            \n",
    "            # Amostragem inteligente de limites\n",
    "            valores_unicos = np.unique(caracteristica)\n",
    "            if len(valores_unicos) > 100:  # Para features com muitos valores √∫nicos\n",
    "                percentis = np.linspace(0, 100, 50)\n",
    "                limites_candidatos = np.percentile(caracteristica, percentis)\n",
    "            else:\n",
    "                limites_candidatos = valores_unicos\n",
    "            \n",
    "            for limite in limites_candidatos:\n",
    "                mascara = caracteristica <= limite\n",
    "                rotulos_esquerda = rotulos[mascara]\n",
    "                rotulos_direita = rotulos[~mascara]\n",
    "                \n",
    "                if len(rotulos_esquerda) < self.min_amostras_divisao or \\\n",
    "                   len(rotulos_direita) < self.min_amostras_divisao:\n",
    "                    continue\n",
    "                \n",
    "                ganho = self._ganho_informacao(rotulos, rotulos_esquerda, rotulos_direita)\n",
    "                \n",
    "                if ganho > melhor_ganho:\n",
    "                    melhor_ganho = ganho\n",
    "                    melhor_caracteristica = idx_caracteristica\n",
    "                    melhor_limite = limite\n",
    "        \n",
    "        return melhor_caracteristica, melhor_limite, melhor_ganho\n",
    "    \n",
    "    def _valor_no(self, rotulos):\n",
    "        if len(rotulos) == 0:\n",
    "            return 0 if self.tipo == 'regressao' else None\n",
    "        \n",
    "        if self.tipo == 'classificacao':\n",
    "            return Counter(rotulos).most_common(1)[0][0]\n",
    "        else:  # regressao\n",
    "            return np.mean(rotulos)\n",
    "    \n",
    "    def _construir_arvore(self, dados, rotulos, profundidade=0):\n",
    "        n_amostras = len(rotulos)\n",
    "        \n",
    "        # Crit√©rios de parada\n",
    "        if (profundidade >= self.profundidade_maxima or \n",
    "            n_amostras < self.min_amostras_divisao * 2 or\n",
    "            len(np.unique(rotulos)) == 1):\n",
    "            \n",
    "            return NoDecisao(valor=self._valor_no(rotulos), n_amostras=n_amostras)\n",
    "        \n",
    "        # Encontrar melhor divis√£o\n",
    "        caracteristica, limite, ganho = self._melhor_divisao(dados, rotulos)\n",
    "        \n",
    "        # Crit√©rio de ganho m√≠nimo\n",
    "        if caracteristica is None or ganho < self.min_ganho_informacao:\n",
    "            return NoDecisao(valor=self._valor_no(rotulos), n_amostras=n_amostras)\n",
    "        \n",
    "        # Aplicar divis√£o\n",
    "        mascara = dados[:, caracteristica] <= limite\n",
    "        esquerda = self._construir_arvore(dados[mascara], rotulos[mascara], profundidade + 1)\n",
    "        direita = self._construir_arvore(dados[~mascara], rotulos[~mascara], profundidade + 1)\n",
    "        \n",
    "        return NoDecisao(caracteristica=caracteristica, limite=limite,\n",
    "                        esquerda=esquerda, direita=direita, \n",
    "                        ganho=ganho, n_amostras=n_amostras)\n",
    "    \n",
    "    # --- FUNCIONALIDADES ---\n",
    "    \n",
    "    def _calcular_importancias(self):\n",
    "        \"\"\"Calcula import√¢ncia das features baseada no ganho de informa√ß√£o\"\"\"\n",
    "        if self.raiz is None:\n",
    "            return\n",
    "        \n",
    "        importancias = np.zeros(100)  # Assumindo at√© 100 features\n",
    "        \n",
    "        def _percorrer_arvore(no):\n",
    "            if no.caracteristica is not None:\n",
    "                # Import√¢ncia = ganho * propor√ß√£o de amostras\n",
    "                importancia = no.ganho * (no.n_amostras / self.raiz.n_amostras)\n",
    "                importancias[no.caracteristica] += importancia\n",
    "                _percorrer_arvore(no.esquerda)\n",
    "                _percorrer_arvore(no.direita)\n",
    "        \n",
    "        _percorrer_arvore(self.raiz)\n",
    "        # Normalizar import√¢ncias\n",
    "        soma_importancias = np.sum(importancias)\n",
    "        if soma_importancias > 0:\n",
    "            self.importancias = importancias / soma_importancias\n",
    "    \n",
    "    def obter_importancias(self, nomes_features=None):\n",
    "        \"\"\"Retorna import√¢ncia das features\"\"\"\n",
    "        if self.importancias is None:\n",
    "            return {}\n",
    "        \n",
    "        if nomes_features is None:\n",
    "            nomes_features = [f'Feature_{i}' for i in range(len(self.importancias))]\n",
    "        \n",
    "        return dict(zip(nomes_features, self.importancias))\n",
    "    \n",
    "    def profundidade_arvore(self):\n",
    "        \"\"\"Calcula a profundidade real da √°rvore\"\"\"\n",
    "        def _profundidade(no):\n",
    "            if no.valor is not None:\n",
    "                return 0\n",
    "            return 1 + max(_profundidade(no.esquerda), _profundidade(no.direita))\n",
    "        \n",
    "        return _profundidade(self.raiz) if self.raiz else 0\n",
    "    \n",
    "    # --- PREVIS√ÉO ---\n",
    "    \n",
    "    def prever(self, dados):\n",
    "        return np.array([self._travessia_arvore(amostra, self.raiz) for amostra in dados])\n",
    "    \n",
    "    def prever_proba(self, dados):\n",
    "        \"\"\"Para classifica√ß√£o: retorna probabilidades\"\"\"\n",
    "        if self.tipo != 'classificacao':\n",
    "            raise ValueError(\"prever_proba s√≥ dispon√≠vel para classifica√ß√£o\")\n",
    "        \n",
    "        def _probabilidades(amostra, no):\n",
    "            if no.valor is not None:\n",
    "                # Retorna distribui√ß√£o de probabilidades\n",
    "                return {no.valor: 1.0}\n",
    "            \n",
    "            if amostra[no.caracteristica] <= no.limite:\n",
    "                return _probabilidades(amostra, no.esquerda)\n",
    "            else:\n",
    "                return _probabilidades(amostra, no.direita)\n",
    "        \n",
    "        return [_probabilidades(amostra, self.raiz) for amostra in dados]\n",
    "    \n",
    "    def _travessia_arvore(self, amostra, no):\n",
    "        if no.valor is not None:\n",
    "            return no.valor\n",
    "        if amostra[no.caracteristica] <= no.limite:\n",
    "            return self._travessia_arvore(amostra, no.esquerda)\n",
    "        return self._travessia_arvore(amostra, no.direita)\n",
    "\n",
    "# --- EXEMPLOS PR√ÅTICOS ---\n",
    "\n",
    "def exemplo_classificacao():\n",
    "    \"\"\"Exemplo com dataset Iris\"\"\"\n",
    "    from sklearn.datasets import load_iris\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import accuracy_score, classification_report\n",
    "    \n",
    "    # Carregar dados\n",
    "    iris = load_iris()\n",
    "    X, y = iris.data, iris.target\n",
    "    \n",
    "    # Dividir treino/teste\n",
    "    X_treino, X_teste, y_treino, y_teste = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Criar e treinar √°rvore\n",
    "    arvore = ArvoreDecisaoAprimorada(\n",
    "        profundidade_maxima=5,\n",
    "        min_amostras_divisao=3,\n",
    "        min_ganho_informacao=0.01,\n",
    "        tipo='classificacao'\n",
    "    )\n",
    "    \n",
    "    arvore.ajustar(X_treino, y_treino)\n",
    "    \n",
    "    # Previs√µes\n",
    "    predicoes = arvore.prever(X_teste)\n",
    "    acuracia = accuracy_score(y_teste, predicoes)\n",
    "    \n",
    "    print(f\"‚úÖ Acur√°cia: {acuracia:.3f}\")\n",
    "    print(f\"üìä Profundidade real: {arvore.profundidade_arvore()}\")\n",
    "    print(\"üéØ Import√¢ncia das features:\")\n",
    "    print(arvore.obter_importancias(iris.feature_names))\n",
    "    \n",
    "    return arvore, acuracia\n",
    "\n",
    "def exemplo_regressao():\n",
    "    \"\"\"Exemplo com dataset de pre√ßos de casas\"\"\"\n",
    "    from sklearn.datasets import fetch_california_housing\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import mean_squared_error, r2_score\n",
    "    \n",
    "    # Carregar dados\n",
    "    housing = fetch_california_housing()\n",
    "    X, y = housing.data, housing.target\n",
    "    \n",
    "    # Amostrar para melhor performance\n",
    "    indices = np.random.choice(len(X), 1000, replace=False)\n",
    "    X, y = X[indices], y[indices]\n",
    "    \n",
    "    X_treino, X_teste, y_treino, y_teste = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # √Årvore de regress√£o\n",
    "    arvore = ArvoreDecisaoAprimorada(\n",
    "        profundidade_maxima=8,\n",
    "        min_amostras_divisao=5,\n",
    "        tipo='regressao'\n",
    "    )\n",
    "    \n",
    "    arvore.ajustar(X_treino, y_treino)\n",
    "    predicoes = arvore.prever(X_teste)\n",
    "    \n",
    "    mse = mean_squared_error(y_teste, predicoes)\n",
    "    r2 = r2_score(y_teste, predicoes)\n",
    "    \n",
    "    print(f\"üìà MSE: {mse:.4f}\")\n",
    "    print(f\"üìä R¬≤ Score: {r2:.4f}\")\n",
    "    print(\"üéØ Features mais importantes:\")\n",
    "    print(arvore.obter_importancias(housing.feature_names))\n",
    "    \n",
    "    return arvore, r2\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"üå≥ √ÅRVORE DE DECIS√ÉO APRIMORADA\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    print(\"\\n1. CLASSIFICA√á√ÉO (Dataset Iris):\")\n",
    "    arvore_class, acc = exemplo_classificacao()\n",
    "    \n",
    "    print(\"\\n2. REGRESS√ÉO (Dataset California Housing):\")\n",
    "    arvore_reg, r2 = exemplo_regressao()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
